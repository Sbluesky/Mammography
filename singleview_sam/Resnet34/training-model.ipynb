{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np \n",
    "from tqdm import tqdm\n",
    "from glob import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 19276 entries, 0 to 19275\nData columns (total 17 columns):\n #   Column          Non-Null Count  Dtype \n---  ------          --------------  ----- \n 0   patient_id      19276 non-null  object\n 1   study_id        19276 non-null  object\n 2   series_id       19276 non-null  object\n 3   image_id        19276 non-null  object\n 4   image_height    19276 non-null  int64 \n 5   image_width     19276 non-null  int64 \n 6   bbox            3549 non-null   object\n 7   blabel          19276 non-null  object\n 8   bsession_id     3549 non-null   object\n 9   gbirad          19276 non-null  object\n 10  gdensity        19276 non-null  object\n 11  gscope          9600 non-null   object\n 12  glaterality     19276 non-null  object\n 13  gview_position  19276 non-null  object\n 14  gsession_id     11352 non-null  object\n 15  multilabel      19276 non-null  object\n 16  fold            19276 non-null  object\ndtypes: int64(2), object(15)\nmemory usage: 2.5+ MB\n"
     ]
    }
   ],
   "source": [
    "labels_df = pd.read_csv(\"/home/single1/BACKUP/SamHUyen/mammo/huyen/csv_singleview.csv\")\n",
    "labels_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#path of image\n",
    "labels_df[\"path\"] = \"/home/single1/BACKUP/SamHUyen/multi_view_mammo_classification/images/\" + labels_df[\"study_id\"] + \"/\" + labels_df[\"image_id\"] + \".png\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 19276/19276 [00:01<00:00, 10018.01it/s]55\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#CROP IMAGE\n",
    "#Data processing\n",
    "miss_img = []\n",
    "list_img = os.listdir(\"/home/single1/BACKUP/SamHUyen/multi_view_mammo_classification/crop-images/crop_images/\")\n",
    "list_crop_img = []\n",
    "for img in list_img:\n",
    "    list_crop_img.append(img.replace(\".png\",\"\"))\n",
    "list_img_id = labels_df[\"image_id\"].values\n",
    "for img_id in tqdm(list_img_id):\n",
    "    if img_id not in list_crop_img:\n",
    "        miss_img.append(img_id)\n",
    "\n",
    "print(len(img_id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Int64Index([2438, 18074], dtype='int64')\nInt64Index([5642], dtype='int64')\nInt64Index([7422], dtype='int64')\nInt64Index([9305], dtype='int64')\nInt64Index([9310], dtype='int64')\nInt64Index([9824], dtype='int64')\nInt64Index([10483], dtype='int64')\nInt64Index([11724], dtype='int64')\nInt64Index([13368], dtype='int64')\nInt64Index([2438, 18074], dtype='int64')\n"
     ]
    }
   ],
   "source": [
    "for i in miss_img:\n",
    "    print(labels_df[labels_df[\"image_id\"] == i].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#crop id khong co trong folder image\n",
    "labels_df = labels_df.drop([2438, 18074,5642,7422,9305,9310,9824,10483,11724,13368])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Training \n",
    "#Custom Batch Generator:\n",
    "import torchvision\n",
    "from glob import glob\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision import transforms\n",
    "from torchvision import models\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "from torch.optim import lr_scheduler\n",
    "from torch import optim\n",
    "from torchvision.utils import make_grid\n",
    "import time\n",
    "from torch.utils.data import Dataset\n",
    "from PIL import Image\n",
    "from PIL import ImageFile\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
    "#import cv2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dataloader\n",
    "class MultiClassMammo(Dataset):\n",
    "    \n",
    "    def __init__(self, dataframe, transform = None):\n",
    "        \n",
    "        self.dataframe = dataframe\n",
    "        self.imagespath = dataframe.path.values\n",
    "        self.transform = transform\n",
    "        self.labels = dataframe.multilabel.values.tolist()\n",
    "        \n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.dataframe)\n",
    "    \n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        \n",
    "        image = Image.open(self.imagespath[index]).convert('RGB')\n",
    "        #image = torch.from_numpy(cv2.imread(self.imagespath[index]))\n",
    "        #torch.reshape(image, (3,1759,1400))\n",
    "        #image = cv2.imread(self.imagespath[index])\n",
    "        label = self.labels[index]\n",
    "        label = label.strip('][').split(', ')\n",
    "        label = np.array(label).astype('float32')\n",
    "        sample = {'image': image, 'label': label}\n",
    "        if self.transform:\n",
    "            image = self.transform(sample['image'])\n",
    "            sample = {'image': image, 'label': label}\n",
    "        \n",
    "        return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#transform images size from (3518, 2800, 3) to (1759,1400,3)\n",
    "tfms = transforms.Compose([transforms.Resize((256, 256)),\n",
    "                           transforms.ToTensor()])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fold: ['train', 'valid', 'holdout']\n",
    "train_dl = MultiClassMammo(labels_df[labels_df[\"fold\"]==\"train\"], transform = tfms) #tfms\n",
    "val_dl = MultiClassMammo(labels_df[labels_df[\"fold\"]==\"valid\"], transform = tfms)\n",
    "#holdout_dl = MultiClassMammo(labels_df[labels_df[\"fold\"]==\"holdout\"], transform = tfms)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[0. 1. 0. 0. 0. 0. 0. 0. 1. 0.]\ntorch.Size([3, 256, 256])\n"
     ]
    }
   ],
   "source": [
    "print(train_dl[1]['label'])\n",
    "print(train_dl[1]['image'].shape)\n",
    "plt.imshow(torchvision.utils.make_grid(train_dl[1]['image']).permute(1, 2, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "class MultiClassifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MultiClassifier, self).__init__()\n",
    "        self.ConvLayer1 = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, 3), # 3, 512, 512 #input : 3 channels, output : 64 channels, kernel size: 3\n",
    "            nn.MaxPool2d(2), # op: 16, 256, 256\n",
    "            nn.ReLU(), # op: 64, 256, 256\n",
    "        )\n",
    "        self.ConvLayer2 = nn.Sequential(\n",
    "            nn.Conv2d(64, 128, 3), # 64, 256, 256   \n",
    "            nn.MaxPool2d(2), #op: 128, 127, 127\n",
    "            nn.ReLU() # op: 128, 127, 127\n",
    "        )\n",
    "        self.ConvLayer3 = nn.Sequential(\n",
    "            nn.Conv2d(128, 256, 3), # 128, 127, 127\n",
    "            nn.MaxPool2d(2), #op: 256, 63, 63\n",
    "            nn.ReLU() #op: 256, 63, 63\n",
    "        )\n",
    "        self.ConvLayer4 = nn.Sequential(\n",
    "            nn.Conv2d(256, 512, 3), # 256, 63, 63\n",
    "            nn.MaxPool2d(2), #op: 512, 30, 30\n",
    "            nn.ReLU(), #op: 512, 30, 30\n",
    "            nn.Dropout(0.2)\n",
    "        )\n",
    "        self.Linear1 = nn.Linear(512 * 30 * 30, 1024) #512 * 14 * 14\n",
    "        self.Linear2 = nn.Linear(1024, 256) #number of nodes input, number of node output\n",
    "        self.Linear3 = nn.Linear(256, 10)\n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.ConvLayer1(x)\n",
    "        x = self.ConvLayer2(x)\n",
    "        x = self.ConvLayer3(x)\n",
    "        x = self.ConvLayer4(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.Linear1(x)\n",
    "        x = self.Linear2(x)\n",
    "        x = self.Linear3(x)\n",
    "        return F.sigmoid(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check cuda\n",
    "def check_cuda():\n",
    "    _cuda = False\n",
    "    if torch.cuda.is_available():\n",
    "        _cuda = True\n",
    "    return _cuda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "is_cuda = check_cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model = MultiClassifier()\n",
    "#Pretrain\n",
    "model = torch.load(\"/home/single1/BACKUP/SamHUyen/mammo/sam/singleview_sam/model/model_epoch.pt\", map_location=torch.device('cuda:0'))\n",
    "\n",
    "if is_cuda:\n",
    "    model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_dataloader = torch.utils.data.DataLoader(train_dl, shuffle = True, batch_size = 2, num_workers = 3)\n",
    "valid_dataloader = torch.utils.data.DataLoader(val_dl, shuffle = True, batch_size = 2, num_workers = 3)\n",
    "\n",
    "#hold_dataloader = torch.utils.data.DataLoader(holdout_dl, shuffle = True, batch_size = 2, num_workers = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr = 0.0001, momentum = 0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "def fit_model(epochs, model, dataloader, phase = 'training', volatile = False):\n",
    "    \n",
    "    pprint(\"Epoch: {}\".format(epochs))\n",
    "\n",
    "    if phase == 'training':\n",
    "        model.train()\n",
    "        \n",
    "    if phase == 'validataion':\n",
    "        model.eval()\n",
    "        volatile = True\n",
    "        \n",
    "    running_loss = []\n",
    "    running_acc = []\n",
    "    b = 0\n",
    "    for i, data in enumerate(dataloader):\n",
    "        \n",
    "\n",
    "        inputs, target = data['image'].cuda(), data['label'].cuda() \n",
    "        \n",
    "        inputs, target = Variable(inputs), Variable(target)\n",
    "        \n",
    "        if phase == 'training':\n",
    "            optimizer.zero_grad()\n",
    "        \n",
    "        #print(inputs)\n",
    "        ops = model(inputs)\n",
    "        \n",
    "        acc_ = []\n",
    "        for i, d in enumerate(ops, 0):\n",
    "           \n",
    "            acc = pred_acc(torch.Tensor.cpu(target[i]), torch.Tensor.cpu(d))\n",
    "            #print(\"True Value: \", torch.Tensor.cpu(target[i]))\n",
    "            #print(\"Predict value: \", torch.round(torch.Tensor.cpu(d)))\n",
    "            #print(acc)\n",
    "            acc_.append(acc)\n",
    "        #print(ops.dtype)\n",
    "        #print(target)\n",
    "        loss = criterion(ops, target)\n",
    "                \n",
    "        running_loss.append(loss.item())\n",
    "        running_acc.append(np.sum(acc_)/len(acc_))\n",
    "        b += 1\n",
    "       \n",
    "        if phase == 'training':\n",
    "            \n",
    "            loss.backward()\n",
    "        \n",
    "            optimizer.step()\n",
    "            \n",
    "    total_batch_loss = np.asarray(running_loss).mean()\n",
    "    total_batch_acc = np.asarray(running_acc).mean()\n",
    "    \n",
    "\n",
    "    pprint(\"{} loss is {} \".format(phase,total_batch_loss))\n",
    "    pprint(\"{} accuracy is {} \".format(phase, total_batch_acc))\n",
    "    \n",
    "    return total_batch_loss, total_batch_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pred_acc(original, predicted):\n",
    "    if torch.all(original.eq(torch.round(predicted))):\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "    #return torch.round(predicted==original).sum().numpy()/len(original)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "  0%|          | 0/5 [00:00<?, ?it/s]'Epoch: 0'\n",
      "'training loss is 0.22100342250255645 '\n",
      "'training accuracy is 0.5490065243179122 '\n",
      "'Epoch: 0'\n",
      " 20%|██        | 1/5 [07:29<29:58, 449.62s/it]'validation loss is 0.23844439386444327 '\n",
      "'validation accuracy is 0.5259695290858726 '\n",
      "'Epoch: 1'\n",
      "'training loss is 0.21992019719575684 '\n",
      "'training accuracy is 0.5474495848161328 '\n",
      "'Epoch: 1'\n",
      " 40%|████      | 2/5 [15:00<22:31, 450.62s/it]'validation loss is 0.23779170957092102 '\n",
      "'validation accuracy is 0.5290858725761773 '\n",
      "'Epoch: 2'\n",
      "'training loss is 0.21933273657822755 '\n",
      "'training accuracy is 0.5464857651245552 '\n",
      "'Epoch: 2'\n",
      " 60%|██████    | 3/5 [22:34<15:03, 451.76s/it]'validation loss is 0.23816868591888543 '\n",
      "'validation accuracy is 0.5169667590027701 '\n",
      "'Epoch: 3'\n",
      "'training loss is 0.21885710482873366 '\n",
      "'training accuracy is 0.5431494661921709 '\n",
      "'Epoch: 3'\n",
      " 80%|████████  | 4/5 [30:11<07:34, 454.01s/it]'validation loss is 0.23754921169832885 '\n",
      "'validation accuracy is 0.5259695290858726 '\n",
      "'Epoch: 4'\n",
      "'training loss is 0.2184653408634272 '\n",
      "'training accuracy is 0.5462633451957295 '\n",
      "'Epoch: 4'\n",
      "100%|██████████| 5/5 [37:44<00:00, 452.92s/it]'validation loss is 0.2363098187299853 '\n",
      "'validation accuracy is 0.5204293628808865 '\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#TRaining model\n",
    "trn_losses = []; trn_acc = []\n",
    "val_losses = []; val_acc = []\n",
    "for i in tqdm(range(0, 5)):\n",
    "    trn_l, trn_a = fit_model(i, model, train_dataloader)\n",
    "    val_l, val_a = fit_model(i, model, valid_dataloader, phase = 'validation')\n",
    "    trn_losses.append(trn_l); trn_acc.append(trn_a)\n",
    "    val_losses.append(val_l); val_acc.append(val_a)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "'Epoch: 0'\n",
      "'validation loss is 0.2507135372020696 '\n",
      "'validation accuracy is 0.8989265927977841 '\n"
     ]
    }
   ],
   "source": [
    "#Test\n",
    "model = torch.load(\"/home/single1/BACKUP/SamHUyen/mammo/sam/singleview_sam/model/model_epoch.pt\", map_location=torch.device('cuda:0'))\n",
    "model = model.eval()\n",
    "\n",
    "val_loss, val_acc = fit_model(0, model, valid_dataloader, phase = 'validation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(\"/home/single1/BACKUP/SamHUyen/mammo/sam/singleview_sam/model/model_imgcrop.pt\",model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}