{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Training \n",
    "#Custom Batch Generator:\n",
    "import pandas as pd\n",
    "import numpy as np \n",
    "from tqdm import tqdm\n",
    "import torchvision\n",
    "from glob import glob\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision import transforms\n",
    "from torchvision import models\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "from torch.optim import lr_scheduler\n",
    "from torch import optim\n",
    "from torchvision.utils import make_grid\n",
    "import time\n",
    "from torch.utils.data import Dataset\n",
    "from PIL import Image\n",
    "\n",
    "import copy\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"/home/single1/BACKUP/SamHUyen/mammo/huyen/csv_singleview.csv\")\n",
    "#path of image\n",
    "df[\"path\"] = \"/home/single1/BACKUP/SamHUyen/multi_view_mammo_classification/crop-images/crop_images/\" + df[\"image_id\"] + \".png\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CROP IMAGE\n",
    "#Data processing\n",
    "df = df.drop([2438, 18074,5642,7422,9305,9310,9824,10483,11724,13368])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dataloader\n",
    "class MultiLabelMammo(Dataset):\n",
    "    \n",
    "    def __init__(self, dataframe, transform = None):\n",
    "        \n",
    "        self.dataframe = dataframe\n",
    "        self.imagespath = dataframe.path.values\n",
    "        self.transform = transform\n",
    "        self.labels = dataframe.multilabel.values.tolist()\n",
    "        \n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.dataframe)\n",
    "    \n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        \n",
    "        image = Image.open(self.imagespath[index]).convert('RGB')\n",
    "        label = self.labels[index]\n",
    "        label = label.strip('][').split(', ')\n",
    "        label = np.array(label).astype('float')\n",
    "        sample = {'image': image, 'label': label}\n",
    "        if self.transform:\n",
    "            image = self.transform(sample['image'])\n",
    "            sample = {'image': image, 'label': label}\n",
    "        \n",
    "        return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#transform images size from (3518, 2800, 3) to (1759,1400,3)\n",
    "tfms = transforms.Compose([transforms.Resize((512, 512)),\n",
    "                           transforms.ToTensor()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fold: ['train', 'valid', 'holdout']\n",
    "train_dl = MultiLabelMammo(df[df[\"fold\"]==\"train\"], transform = tfms) \n",
    "val_dl = MultiLabelMammo(df[df[\"fold\"]==\"valid\"], transform = tfms)\n",
    "# holdout_dl = MultiLabelMammo(df[df[\"fold\"]==\"valid\"], transform = tfms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = torch.utils.data.DataLoader(train_dl, shuffle = True, batch_size = 4, num_workers = 3)\n",
    "val_dataloader = torch.utils.data.DataLoader(val_dl, shuffle = True, batch_size = 1, num_workers = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() \n",
    "                                  else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_mod = models.resnet34(pretrained=True)\n",
    "\n",
    "num_ftrs = res_mod.fc.in_features\n",
    "res_mod.fc = nn.Linear(num_ftrs, 10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "conv1\nbn1\nrelu\nmaxpool\nlayer1\nlayer2\nlayer3\nlayer4\navgpool\nfc\n"
     ]
    }
   ],
   "source": [
    "for name, child in res_mod.named_children():\n",
    "    print(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_mod = res_mod.to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Observe that all parameters are being optimized\n",
    "optimizer_ft = optim.SGD(res_mod.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "# Decay LR by a factor of 0.1 every 10 epochs\n",
    "# exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=20, gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, criterion, optimizer, num_epochs=10):\n",
    "    since = time.time()\n",
    "\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_acc = 0.0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
    "        print('-' * 10)\n",
    "\n",
    "        # Each epoch has a training and validation phase\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                # scheduler.step()\n",
    "                model.train()  # Set model to training mode\n",
    "            else:\n",
    "                model.eval()   # Set model to evaluate mode\n",
    "\n",
    "            current_loss = 0.0\n",
    "            current_corrects = 0\n",
    "\n",
    "            # Here's where the training happens\n",
    "            print('Iterating through data...')\n",
    "\n",
    "\n",
    "            for i, data in enumerate(tqdm(globals()[f'{phase}_dataloader'])):\n",
    "                \n",
    "                inputs = data['image'].to(device)\n",
    "                labels = data['label'].to(device)\n",
    "                labels = labels.long()\n",
    "                print(\"\\n labels \", labels)\n",
    "                #labels = torch.max(labels, 1)[1]\n",
    "\n",
    "                # We need to zero the gradients, don't forget it\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # Time to carry out the forward training poss\n",
    "                # We only need to log the loss stats if we are in training phase\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    outputs = model(inputs)\n",
    "                    print(\"outputs: \", outputs)\n",
    "                    #_, preds = torch.max(outputs, 1)\n",
    "                    preds = convert(outputs)\n",
    "                    loss = criterion(preds, labels) #outputs\n",
    "\n",
    "                    # backward + optimize only if in training phase\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                # We want variables to hold the loss statistics\n",
    "                current_loss += loss.item() * inputs.size(0)\n",
    "                current_corrects += torch.sum(preds == labels.data)\n",
    "                print(\"\\n preds \", preds)\n",
    "                print(\"\\n true values \", labels.data)\n",
    "                print(\" current_corrects \", current_corrects)\n",
    "\n",
    "            epoch_loss = current_loss / (13488 if phase == 'train' else 2888)\n",
    "            epoch_acc = current_corrects.double() / (13488 if phase == 'train' else 2888)\n",
    "\n",
    "            print('{} Loss: {:.4f} Acc: {:.4f}'.format(\n",
    "                phase, epoch_loss, epoch_acc))\n",
    "\n",
    "            # Make a copy of the model if the accuracy on the validation set has improved\n",
    "            if phase == 'val':\n",
    "                if epoch_acc > best_acc:\n",
    "                    best_acc = epoch_acc\n",
    "                    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "                    torch.save(best_model_wts, '/home/single1/BACKUP/SamHUyen/mammo/sam/singleview_sam/model/BEST_redmodTest.pt')            \n",
    "            \n",
    "                torch.save(model.state_dict(), '/home/single1/BACKUP/SamHUyen/mammo/sam/singleview_sam/model/redmod_test.pt')\n",
    "\n",
    "        print()\n",
    "\n",
    "    time_since = time.time() - since\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(\n",
    "        time_since // 60, time_since % 60))\n",
    "    print('Best val Acc: {:4f}'.format(best_acc))\n",
    "\n",
    "    # Now we'll load in the best model weights and return it\n",
    "    # model.load_state_dict(best_model_wts)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "  0%|          | 0/3370 [00:00<?, ?it/s]Epoch 0/19\n",
      "----------\n",
      "Iterating through data...\n",
      "100%|██████████| 3370/3370 [02:45<00:00, 20.40it/s]\n",
      "  0%|          | 0/2888 [00:00<?, ?it/s]train Loss: 0.8830 Acc: 0.7055\n",
      "Iterating through data...\n",
      "100%|██████████| 2888/2888 [00:29<00:00, 98.42it/s]\n",
      "  0%|          | 0/3370 [00:00<?, ?it/s]val Loss: 0.8392 Acc: 0.7497\n",
      "\n",
      "Epoch 1/19\n",
      "----------\n",
      "Iterating through data...\n",
      "100%|██████████| 3370/3370 [02:45<00:00, 20.35it/s]\n",
      "  0%|          | 0/2888 [00:00<?, ?it/s]train Loss: 0.7874 Acc: 0.7522\n",
      "Iterating through data...\n",
      "100%|██████████| 2888/2888 [00:28<00:00, 101.36it/s]\n",
      "val Loss: 0.7849 Acc: 0.7628\n",
      "  0%|          | 0/3370 [00:00<?, ?it/s]\n",
      "Epoch 2/19\n",
      "----------\n",
      "Iterating through data...\n",
      "100%|██████████| 3370/3370 [02:46<00:00, 20.26it/s]\n",
      "  0%|          | 0/2888 [00:00<?, ?it/s]train Loss: 0.7540 Acc: 0.7591\n",
      "Iterating through data...\n",
      "100%|██████████| 2888/2888 [00:28<00:00, 100.03it/s]\n",
      "val Loss: 0.7394 Acc: 0.7666\n",
      "  0%|          | 0/3370 [00:00<?, ?it/s]\n",
      "Epoch 3/19\n",
      "----------\n",
      "Iterating through data...\n",
      "100%|██████████| 3370/3370 [03:31<00:00, 15.90it/s]\n",
      "  0%|          | 0/2888 [00:00<?, ?it/s]train Loss: 0.7314 Acc: 0.7661\n",
      "Iterating through data...\n",
      "100%|██████████| 2888/2888 [00:38<00:00, 75.08it/s]\n",
      "val Loss: 0.7377 Acc: 0.7687\n",
      "  0%|          | 0/3370 [00:00<?, ?it/s]\n",
      "Epoch 4/19\n",
      "----------\n",
      "Iterating through data...\n",
      "100%|██████████| 3370/3370 [04:42<00:00, 11.93it/s]\n",
      "  0%|          | 0/2888 [00:00<?, ?it/s]train Loss: 0.7015 Acc: 0.7736\n",
      "Iterating through data...\n",
      "100%|██████████| 2888/2888 [00:37<00:00, 77.16it/s]\n",
      "val Loss: 0.7001 Acc: 0.7867\n",
      "  0%|          | 0/3370 [00:00<?, ?it/s]\n",
      "Epoch 5/19\n",
      "----------\n",
      "Iterating through data...\n",
      "100%|██████████| 3370/3370 [04:37<00:00, 12.16it/s]\n",
      "  0%|          | 0/2888 [00:00<?, ?it/s]train Loss: 0.6736 Acc: 0.7792\n",
      "Iterating through data...\n",
      "100%|██████████| 2888/2888 [00:36<00:00, 78.18it/s]\n",
      "val Loss: 0.6687 Acc: 0.7988\n",
      "  0%|          | 0/3370 [00:00<?, ?it/s]\n",
      "Epoch 6/19\n",
      "----------\n",
      "Iterating through data...\n",
      "100%|██████████| 3370/3370 [03:04<00:00, 18.31it/s]\n",
      "  0%|          | 0/2888 [00:00<?, ?it/s]train Loss: 0.6417 Acc: 0.7911\n",
      "Iterating through data...\n",
      "100%|██████████| 2888/2888 [00:37<00:00, 77.85it/s]\n",
      "val Loss: 0.6314 Acc: 0.7961\n",
      "  0%|          | 0/3370 [00:00<?, ?it/s]\n",
      "Epoch 7/19\n",
      "----------\n",
      "Iterating through data...\n",
      "100%|██████████| 3370/3370 [04:50<00:00, 11.59it/s]\n",
      "  0%|          | 0/2888 [00:00<?, ?it/s]train Loss: 0.6067 Acc: 0.8015\n",
      "Iterating through data...\n",
      "100%|██████████| 2888/2888 [00:37<00:00, 77.40it/s]\n",
      "val Loss: 0.5980 Acc: 0.8127\n",
      "  0%|          | 0/3370 [00:00<?, ?it/s]\n",
      "Epoch 8/19\n",
      "----------\n",
      "Iterating through data...\n",
      "100%|██████████| 3370/3370 [04:51<00:00, 11.58it/s]\n",
      "  0%|          | 0/2888 [00:00<?, ?it/s]train Loss: 0.5724 Acc: 0.8107\n",
      "Iterating through data...\n",
      "100%|██████████| 2888/2888 [00:37<00:00, 77.38it/s]\n",
      "val Loss: 0.6678 Acc: 0.7819\n",
      "  0%|          | 0/3370 [00:00<?, ?it/s]\n",
      "Epoch 9/19\n",
      "----------\n",
      "Iterating through data...\n",
      "100%|██████████| 3370/3370 [03:25<00:00, 16.43it/s]\n",
      "  0%|          | 0/2888 [00:00<?, ?it/s]train Loss: 0.5310 Acc: 0.8237\n",
      "Iterating through data...\n",
      "100%|██████████| 2888/2888 [00:32<00:00, 90.13it/s]\n",
      "val Loss: 0.6374 Acc: 0.8002\n",
      "  0%|          | 0/3370 [00:00<?, ?it/s]\n",
      "Epoch 10/19\n",
      "----------\n",
      "Iterating through data...\n",
      "100%|██████████| 3370/3370 [02:47<00:00, 20.07it/s]\n",
      "  0%|          | 0/2888 [00:00<?, ?it/s]train Loss: 0.4917 Acc: 0.8368\n",
      "Iterating through data...\n",
      "100%|██████████| 2888/2888 [00:32<00:00, 89.94it/s]\n",
      "val Loss: 0.5354 Acc: 0.8286\n",
      "  0%|          | 0/3370 [00:00<?, ?it/s]\n",
      "Epoch 11/19\n",
      "----------\n",
      "Iterating through data...\n",
      "100%|██████████| 3370/3370 [02:47<00:00, 20.09it/s]\n",
      "  0%|          | 0/2888 [00:00<?, ?it/s]train Loss: 0.4454 Acc: 0.8513\n",
      "Iterating through data...\n",
      "100%|██████████| 2888/2888 [00:31<00:00, 92.60it/s]\n",
      "val Loss: 0.5850 Acc: 0.8161\n",
      "  0%|          | 0/3370 [00:00<?, ?it/s]\n",
      "Epoch 12/19\n",
      "----------\n",
      "Iterating through data...\n",
      "100%|██████████| 3370/3370 [02:47<00:00, 20.15it/s]\n",
      "  0%|          | 0/2888 [00:00<?, ?it/s]train Loss: 0.4036 Acc: 0.8650\n",
      "Iterating through data...\n",
      "100%|██████████| 2888/2888 [00:31<00:00, 91.97it/s]\n",
      "val Loss: 0.5118 Acc: 0.8452\n",
      "  0%|          | 0/3370 [00:00<?, ?it/s]\n",
      "Epoch 13/19\n",
      "----------\n",
      "Iterating through data...\n",
      "100%|██████████| 3370/3370 [02:47<00:00, 20.13it/s]\n",
      "  0%|          | 0/2888 [00:00<?, ?it/s]train Loss: 0.3568 Acc: 0.8797\n",
      "Iterating through data...\n",
      "100%|██████████| 2888/2888 [00:31<00:00, 92.96it/s]\n",
      "val Loss: 0.4904 Acc: 0.8553\n",
      "  0%|          | 0/3370 [00:00<?, ?it/s]\n",
      "Epoch 14/19\n",
      "----------\n",
      "Iterating through data...\n",
      "100%|██████████| 3370/3370 [02:47<00:00, 20.15it/s]\n",
      "  0%|          | 0/2888 [00:00<?, ?it/s]train Loss: 0.3195 Acc: 0.8892\n",
      "Iterating through data...\n",
      "100%|██████████| 2888/2888 [00:31<00:00, 93.07it/s]\n",
      "val Loss: 0.5375 Acc: 0.8456\n",
      "  0%|          | 0/3370 [00:00<?, ?it/s]\n",
      "Epoch 15/19\n",
      "----------\n",
      "Iterating through data...\n",
      "100%|██████████| 3370/3370 [02:47<00:00, 20.09it/s]\n",
      "  0%|          | 0/2888 [00:00<?, ?it/s]train Loss: 0.2822 Acc: 0.9011\n",
      "Iterating through data...\n",
      "100%|██████████| 2888/2888 [00:31<00:00, 92.73it/s]\n",
      "val Loss: 0.4642 Acc: 0.8726\n",
      "  0%|          | 0/3370 [00:00<?, ?it/s]\n",
      "Epoch 16/19\n",
      "----------\n",
      "Iterating through data...\n",
      "100%|██████████| 3370/3370 [02:47<00:00, 20.15it/s]\n",
      "  0%|          | 0/2888 [00:00<?, ?it/s]train Loss: 0.2390 Acc: 0.9161\n",
      "Iterating through data...\n",
      "100%|██████████| 2888/2888 [00:31<00:00, 92.79it/s]\n",
      "val Loss: 0.4512 Acc: 0.8792\n",
      "  0%|          | 0/3370 [00:00<?, ?it/s]\n",
      "Epoch 17/19\n",
      "----------\n",
      "Iterating through data...\n",
      "100%|██████████| 3370/3370 [02:47<00:00, 20.17it/s]\n",
      "  0%|          | 0/2888 [00:00<?, ?it/s]train Loss: 0.2106 Acc: 0.9256\n",
      "Iterating through data...\n",
      "100%|██████████| 2888/2888 [00:31<00:00, 92.98it/s]\n",
      "val Loss: 0.5088 Acc: 0.8774\n",
      "  0%|          | 0/3370 [00:00<?, ?it/s]\n",
      "Epoch 18/19\n",
      "----------\n",
      "Iterating through data...\n",
      "100%|██████████| 3370/3370 [02:46<00:00, 20.19it/s]\n",
      "  0%|          | 0/2888 [00:00<?, ?it/s]train Loss: 0.1983 Acc: 0.9296\n",
      "Iterating through data...\n",
      "100%|██████████| 2888/2888 [00:30<00:00, 93.67it/s]\n",
      "val Loss: 0.5244 Acc: 0.8560\n",
      "  0%|          | 0/3370 [00:00<?, ?it/s]\n",
      "Epoch 19/19\n",
      "----------\n",
      "Iterating through data...\n",
      "100%|██████████| 3370/3370 [02:46<00:00, 20.20it/s]\n",
      "  0%|          | 0/2888 [00:00<?, ?it/s]train Loss: 0.1818 Acc: 0.9363\n",
      "Iterating through data...\n",
      "100%|██████████| 2888/2888 [00:30<00:00, 93.49it/s]\n",
      "val Loss: 0.5283 Acc: 0.8715\n",
      "\n",
      "Training complete in 76m 38s\n",
      "Best val Acc: 0.879155\n"
     ]
    }
   ],
   "source": [
    "from PIL import ImageFile\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
    "train_model(res_mod, criterion, optimizer_ft, num_epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "error",
     "ename": "RuntimeError",
     "evalue": "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 10.75 GiB total capacity; 1.17 GiB already allocated; 31.50 MiB free; 1.19 GiB reserved in total by PyTorch)",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-64-c7911706cba1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mPIL\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mImageFile\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mImageFile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLOAD_TRUNCATED_IMAGES\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres_mod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer_ft\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-62-e77ff0314f3b>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(model, criterion, optimizer, num_epochs)\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0msince\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mbest_model_wts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mbest_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.8/copy.py\u001b[0m in \u001b[0;36mdeepcopy\u001b[0;34m(x, memo, _nil)\u001b[0m\n\u001b[1;32m    170\u001b[0m                     \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 172\u001b[0;31m                     \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_reconstruct\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mrv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    173\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    174\u001b[0m     \u001b[0;31m# If is its own copy, don't memoize.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.8/copy.py\u001b[0m in \u001b[0;36m_reconstruct\u001b[0;34m(x, memo, func, args, state, listiter, dictiter, deepcopy)\u001b[0m\n\u001b[1;32m    294\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdictiter\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m                 \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 296\u001b[0;31m                 \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    297\u001b[0m                 \u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    298\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.8/copy.py\u001b[0m in \u001b[0;36mdeepcopy\u001b[0;34m(x, memo, _nil)\u001b[0m\n\u001b[1;32m    151\u001b[0m             \u001b[0mcopier\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"__deepcopy__\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mcopier\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 153\u001b[0;31m                 \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcopier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmemo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    154\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m                 \u001b[0mreductor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdispatch_table\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36m__deepcopy__\u001b[0;34m(self, memo)\u001b[0m\n\u001b[1;32m     53\u001b[0m                 \u001b[0mnew_tensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m                 \u001b[0mnew_storage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstorage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__deepcopy__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmemo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_quantized\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m                     \u001b[0;31m# quantizer_params can be different type based on torch attribute\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/storage.py\u001b[0m in \u001b[0;36m__deepcopy__\u001b[0;34m(self, memo)\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cdata\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmemo\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mmemo\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cdata\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m         \u001b[0mnew_storage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m         \u001b[0mmemo\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cdata\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_storage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mnew_storage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/storage.py\u001b[0m in \u001b[0;36mclone\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     42\u001b[0m         \u001b[0mdevice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_device\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_cuda\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/cuda/__init__.py\u001b[0m in \u001b[0;36m_lazy_new\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m    460\u001b[0m     \u001b[0;31m# We may need to call lazy init again if we are a forked child\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    461\u001b[0m     \u001b[0;31m# del _CudaBase.__new__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 462\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_CudaBase\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__new__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    463\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    464\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 10.75 GiB total capacity; 1.17 GiB already allocated; 31.50 MiB free; 1.19 GiB reserved in total by PyTorch)"
     ]
    }
   ],
   "source": [
    "from PIL import ImageFile\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
    "train_model(res_mod, criterion, optimizer_ft, num_epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([0, 1, 0, 1, 1, 0])"
      ]
     },
     "metadata": {},
     "execution_count": 20
    }
   ],
   "source": [
    " third_tensor = torch.cat((torch.tensor([0,1,0]), torch.tensor([1,1,0])), 0)\n",
    " third_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = torch.tensor([[0, 0, 1, 0, 0, 0, 0, 0, 1, 0],\n",
    "        [0, 1, 0, 0, 0, 0, 0, 0, 0, 1],\n",
    "        [0, 0, 1, 0, 0, 0, 0, 0, 1, 0],\n",
    "        [0, 0, 1, 0, 0, 0, 0, 0, 0, 1]], device='cuda:0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([[0, 0, 1, 0, 0, 0, 0, 0, 1, 0],\n",
       "        [0, 1, 0, 0, 0, 0, 0, 0, 0, 1],\n",
       "        [0, 0, 1, 0, 0, 0, 0, 0, 1, 0],\n",
       "        [0, 0, 1, 0, 0, 0, 0, 0, 0, 1]], device='cuda:0')"
      ]
     },
     "metadata": {},
     "execution_count": 27
    }
   ],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs=  torch.tensor([[ 3.3211, -5.3717, 12.0751,  4.2464,  5.3956, -0.3999, -4.8750, -5.1574,\n",
    "         -5.2155, -5.0423],\n",
    "        [ 2.3364, 13.5524,  6.9783,  2.3466,  0.7610, -4.3412, -5.7815, -5.6116,\n",
    "         -5.8110, -5.7357],\n",
    "        [ 2.4455, 12.6521,  6.3002,  2.1030,  0.9366, -3.8087, -5.5127, -5.3128,\n",
    "         -5.4292, -5.4021],\n",
    "        [ 2.6582, 10.8746,  4.4139,  4.2448,  0.6733, -3.1573, -5.2087, -5.1427,\n",
    "         -5.2411, -5.2520]], device='cuda:0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([[-4.8750, -5.1574, -5.2155, -5.0423],\n",
       "        [-5.7815, -5.6116, -5.8110, -5.7357],\n",
       "        [-5.5127, -5.3128, -5.4292, -5.4021],\n",
       "        [-5.2087, -5.1427, -5.2411, -5.2520]], device='cuda:0')"
      ]
     },
     "metadata": {},
     "execution_count": 51
    }
   ],
   "source": [
    "outputs[:,6:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert(outputs):\n",
    "    birads = torch.max(outputs[:,:6],1)[1] #get maximmum indices of birad\n",
    "    density = torch.max(outputs[:,6:],1)[1]\n",
    "    result = torch.zeros((4,10))\n",
    "    for ind in range(0,4):\n",
    "        result[ind,birads[ind]] = 1\n",
    "        result[ind,6 + density[ind]] = 1\n",
    "    return result\n",
    "#print(birads)\n",
    "#print(density)\n",
    "#print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "metadata": {},
     "execution_count": 65
    }
   ],
   "source": [
    "len(outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}